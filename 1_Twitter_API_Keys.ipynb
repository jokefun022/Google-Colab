{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOeh32E+yEERuj/4KQ3z5c+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jokefun022/Google-Colab/blob/main/1_Twitter_API_Keys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install tweepy pandas --quiet\n",
        "\n",
        "# Import required libraries\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import time\n",
        "from IPython.display import FileLink\n",
        "\n",
        "# Twitter API Bearer Token\n",
        "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAH4pxgEAAAAAqmf6%2F05DaW95WHMAKxWwziN1ucI%3D8vvUZd1M8qFhskeUPIP09ikVj79HAUeNi1rVH9j3hGYyQa8LwF\"  # Replace with your Bearer Token\n",
        "\n",
        "# Initialize Tweepy Client\n",
        "client = tweepy.Client(bearer_token=bearer_token)\n",
        "\n",
        "# Define the search query\n",
        "search_query = \"cyberbullying roman urdu -is:retweet -is:reply\"\n",
        "max_results = 100  # API allows up to 100 tweets per request\n",
        "total_tweets = 400  # Total number of tweets to fetch\n",
        "\n",
        "# List to store tweet data\n",
        "tweets_data = []\n",
        "\n",
        "try:\n",
        "    # Pagination to fetch tweets\n",
        "    next_token = None\n",
        "    while len(tweets_data) < total_tweets:\n",
        "        # Fetch tweets\n",
        "        response = client.search_recent_tweets(\n",
        "            query=search_query,\n",
        "            tweet_fields=[\"id\", \"text\", \"created_at\", \"public_metrics\", \"source\", \"author_id\", \"lang\"],\n",
        "            max_results=min(max_results, total_tweets - len(tweets_data)),  # Ensure not exceeding total tweets\n",
        "            next_token=next_token  # Use next_token for pagination\n",
        "        )\n",
        "\n",
        "        # Process the response\n",
        "        if response.data:\n",
        "            for tweet in response.data:\n",
        "                tweets_data.append({\n",
        "                    \"Tweet ID\": tweet.id,\n",
        "                    \"Text\": tweet.text,\n",
        "                    \"Date Created\": tweet.created_at,\n",
        "                    \"Source\": tweet.source,\n",
        "                    \"Likes\": tweet.public_metrics[\"like_count\"],\n",
        "                    \"Retweets\": tweet.public_metrics[\"retweet_count\"],\n",
        "                    \"Author ID\": tweet.author_id,\n",
        "                    \"Language\": tweet.lang\n",
        "                })\n",
        "\n",
        "        # Check if there's another page of tweets\n",
        "        next_token = response.meta.get(\"next_token\")\n",
        "        if not next_token:\n",
        "            break  # Exit loop if no more pages\n",
        "\n",
        "        # Add a delay to respect rate limits\n",
        "        time.sleep(2)  # Pause for 2 seconds between requests\n",
        "\n",
        "    # Create a DataFrame\n",
        "    tweets_df = pd.DataFrame(tweets_data)\n",
        "\n",
        "    # Save to CSV\n",
        "    file_name = \"cyberbullying_roman_urdu_tweets.csv\"\n",
        "    tweets_df.to_csv(file_name, index=False)\n",
        "    print(f\"Successfully retrieved {len(tweets_df)} tweets and saved to '{file_name}'.\")\n",
        "\n",
        "    # Provide download link\n",
        "    display(FileLink(file_name))\n",
        "\n",
        "except tweepy.errors.TooManyRequests as e:\n",
        "    print(\"Rate limit exceeded. Please try again later.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "lZ2EmxxZdn0E",
        "outputId": "926f80d0-63d3-4e88-836f-4301e24d720d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully retrieved 0 tweets and saved to 'cyberbullying_roman_urdu_tweets.csv'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/cyberbullying_roman_urdu_tweets.csv"
            ],
            "text/html": [
              "<a href='cyberbullying_roman_urdu_tweets.csv' target='_blank'>cyberbullying_roman_urdu_tweets.csv</a><br>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}